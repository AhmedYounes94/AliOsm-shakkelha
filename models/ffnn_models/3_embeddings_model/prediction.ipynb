{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSTANTS_PATH = '../../../helpers/constants'\n",
    "DATASET_PATH = '../../../dataset'\n",
    "CHARS_NUM = 50\n",
    "CLASSES_NUM = 15\n",
    "\n",
    "with open(CONSTANTS_PATH + '/ARABIC_LETTERS_LIST.pickle', 'rb') as file:\n",
    "    ARABIC_LETTERS_LIST = pkl.load(file)\n",
    "\n",
    "with open(CONSTANTS_PATH + '/DIACRITICS_LIST.pickle', 'rb') as file:\n",
    "    DIACRITICS_LIST = pkl.load(file)\n",
    "\n",
    "with open(CONSTANTS_PATH + '/FFNN_SMALL_CHARACTERS_MAPPING.pickle', 'rb') as file:\n",
    "    CHARACTERS_MAPPING = pkl.load(file)\n",
    "\n",
    "with open(CONSTANTS_PATH + '/FFNN_CLASSES_MAPPING.pickle', 'rb') as file:\n",
    "    CLASSES_MAPPING = pkl.load(file)\n",
    "\n",
    "with open(CONSTANTS_PATH + '/FFNN_REV_CLASSES_MAPPING.pickle', 'rb') as file:\n",
    "    REV_CLASSES_MAPPING = pkl.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model.ckpt')\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.train.AdamOptimizer(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = None\n",
    "Y_test = None\n",
    "with open(DATASET_PATH + '/X_test.pickle', 'rb') as X_test_file, \\\n",
    "         open(DATASET_PATH + '/Y_test.pickle', 'rb') as Y_test_file:\n",
    "    X_test = pkl.load(X_test_file)\n",
    "    Y_test = pkl.load(Y_test_file)\n",
    "print('Testing examples:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, X, Y, batch_size):\n",
    "        self.X, self.Y = X, Y\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_batch = np.asarray(self.X[idx * self.batch_size:(idx + 1) * self.batch_size])\n",
    "        Y_batch = np.asarray(self.Y[idx * self.batch_size:(idx + 1) * self.batch_size])\n",
    "        \n",
    "        X_tmp = list()\n",
    "        for x in X_batch:\n",
    "            before_need = x[0]\n",
    "            after_need = x[-1]\n",
    "            x_new = list()\n",
    "            x_new.extend([1] * before_need)\n",
    "            x_new.extend(x[1:-1])\n",
    "            x_new.extend([1] * after_need)\n",
    "            X_tmp.append(np.asarray(x_new))\n",
    "        \n",
    "        X_batch = np.asarray(X_tmp)\n",
    "        Y_batch = np.asarray(Y_batch)\n",
    "        \n",
    "        return X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(X_test, Y_test, len(X_test))\n",
    "\n",
    "XY_test = list()\n",
    "for batch in range(len(test_generator)):\n",
    "    XY_test.append(test_generator[batch])\n",
    "X, Y = zip(*XY_test)\n",
    "\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "X = np.squeeze(X)\n",
    "Y = np.squeeze(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X, Y, batch_size=512)\n",
    "print('Accuracy: %s%%' % round(acc * 100, 2))\n",
    "print('Loss: %s' % round(loss, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(line):\n",
    "    equal = 0\n",
    "    not_equal = 0\n",
    "    output = ''\n",
    "    \n",
    "    for idx, ch in enumerate(line):\n",
    "        if ch in DIACRITICS_LIST:\n",
    "            continue\n",
    "        \n",
    "        output += ch\n",
    "        \n",
    "        if ch not in ARABIC_LETTERS_LIST:\n",
    "            continue\n",
    "            \n",
    "        y_true = [0] * CLASSES_NUM\n",
    "        if idx + 1 < len(line) and line[idx + 1] in DIACRITICS_LIST:\n",
    "            ch_diac = line[idx + 1]\n",
    "            if idx + 2 < len(line) and line[idx + 2] in DIACRITICS_LIST and ch_diac + line[idx + 2] in CLASSES_MAPPING:\n",
    "                ch_diac += line[idx + 2]\n",
    "            y_true[CLASSES_MAPPING[ch_diac]] = 1\n",
    "        else:\n",
    "            y_true[0] = 1\n",
    "        y_true = np.asarray(y_true).reshape(1, -1)\n",
    "\n",
    "        before = list()\n",
    "        after = list()\n",
    "\n",
    "        for idxb in range(idx - 1, -1, -1):\n",
    "            if len(before) >= CHARS_NUM:\n",
    "                break\n",
    "            if line[idxb] not in DIACRITICS_LIST:\n",
    "                before.append(line[idxb])\n",
    "        before = before[::-1]\n",
    "        before_need = CHARS_NUM - len(before)\n",
    "\n",
    "        for idxa in range(idx, len(line)):\n",
    "            if len(after) >= CHARS_NUM:\n",
    "                break\n",
    "            if line[idxa] not in DIACRITICS_LIST:\n",
    "                after.append(line[idxa])\n",
    "        after_need = CHARS_NUM - len(after)\n",
    "\n",
    "        x = list()\n",
    "        x.extend([1] * before_need)\n",
    "        for ch in before:\n",
    "            try:\n",
    "                x.append(CHARACTERS_MAPPING[ch])\n",
    "            except:\n",
    "                x.append(0)\n",
    "        for ch in after:\n",
    "            try:\n",
    "                x.append(CHARACTERS_MAPPING[ch])\n",
    "            except:\n",
    "                x.append(0)\n",
    "        x.extend([1] * after_need)\n",
    "        x = np.asarray(x)\n",
    "\n",
    "        x = np.asarray(x).reshape(1, -1)\n",
    "        y_pred = model.predict(x)\n",
    "        \n",
    "        y_true_mx = np.argmax(y_true)\n",
    "        y_pred_mx = np.argmax(y_pred)\n",
    "        \n",
    "        equal += (y_true_mx == y_pred_mx)\n",
    "        not_equal += (y_true_mx != y_pred_mx)\n",
    "        \n",
    "        if y_pred_mx == 0:\n",
    "            continue\n",
    "        \n",
    "        output += REV_CLASSES_MAPPING[y_pred_mx]\n",
    "    return output, equal, not_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = 'اللَّهُمَّ عَلِّمْنَا مَا يَنْفَعُنَا وَإِنْفَعْنَا بِمَا عَلَّمْتَنَا إِنَّكَ أَنْتَ العَلِيمُ الحَكِيمُ'\n",
    "prediction = predict(text)\n",
    "print(prediction[0], prediction[1], prediction[2], prediction[1] / (prediction[1] + prediction[2]) * 100, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
